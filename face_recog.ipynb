{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face_recog.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPxyANQav17fOfKkE1jX4fc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_0uWDtoAniPN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"error","timestamp":1590893325320,"user_tz":-540,"elapsed":818,"user":{"displayName":"이혜빈","photoUrl":"","userId":"15655053117229953023"}},"outputId":"a7b0401e-84e5-4995-9ff2-3101eb1ceba8"},"source":["# face_recog.py\n","\n","import face_recognition\n","import cv2\n","import camera\n","import os\n","import numpy as np\n","\n","class FaceRecog():\n","    def __init__(self):\n","        # Using OpenCV to capture from device 0. If you have trouble capturing\n","        # from a webcam, comment the line below out and use a video file\n","        # instead.\n","        self.camera = camera.VideoCamera()\n","\n","        self.known_face_encodings = []\n","        self.known_face_names = []\n","\n","        # Load sample pictures and learn how to recognize it.\n","        dirname = 'knowns'\n","        files = os.listdir(dirname)\n","        for filename in files:\n","            name, ext = os.path.splitext(filename)\n","            if ext == '.jpg':\n","                self.known_face_names.append(name)\n","                pathname = os.path.join(dirname, filename)\n","                img = face_recognition.load_image_file(pathname)\n","                face_encoding = face_recognition.face_encodings(img)[0]\n","                self.known_face_encodings.append(face_encoding)\n","\n","        # Initialize some variables\n","        self.face_locations = []\n","        self.face_encodings = []\n","        self.face_names = []\n","        self.process_this_frame = True\n","\n","    def __del__(self):\n","        del self.camera\n","\n","    def get_frame(self):\n","        # Grab a single frame of video\n","        frame = self.camera.get_frame()\n","\n","        # Resize frame of video to 1/4 size for faster face recognition processing\n","        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n","\n","        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n","        rgb_small_frame = small_frame[:, :, ::-1]\n","\n","        # Only process every other frame of video to save time\n","        if self.process_this_frame:\n","            # Find all the faces and face encodings in the current frame of video\n","            self.face_locations = face_recognition.face_locations(rgb_small_frame)\n","            self.face_encodings = face_recognition.face_encodings(rgb_small_frame, self.face_locations)\n","\n","            self.face_names = []\n","            for face_encoding in self.face_encodings:\n","                # See if the face is a match for the known face(s)\n","                distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n","                min_value = min(distances)\n","\n","                # tolerance: How much distance between faces to consider it a match. Lower is more strict.\n","                # 0.6 is typical best performance.\n","                name = \"Unknown\"\n","                if min_value < 0.6:\n","                    index = np.argmin(distances)\n","                    name = self.known_face_names[index]\n","\n","                self.face_names.append(name)\n","\n","        self.process_this_frame = not self.process_this_frame\n","\n","        # Display the results\n","        for (top, right, bottom, left), name in zip(self.face_locations, self.face_names):\n","            # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n","            top *= 4\n","            right *= 4\n","            bottom *= 4\n","            left *= 4\n","\n","            # Draw a box around the face\n","            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n","\n","            # Draw a label with a name below the face\n","            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n","            font = cv2.FONT_HERSHEY_DUPLEX\n","            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n","\n","        return frame\n","\n","    def get_jpg_bytes(self):\n","        frame = self.get_frame()\n","        # We are using Motion JPEG, but OpenCV defaults to capture raw images,\n","        # so we must encode it into JPEG in order to correctly display the\n","        # video stream.\n","        ret, jpg = cv2.imencode('.jpg', frame)\n","        return jpg.tobytes()\n","\n","\n","if __name__ == '__main__':\n","    face_recog = FaceRecog()\n","    print(face_recog.known_face_names)\n","    while True:\n","        frame = face_recog.get_frame()\n","\n","        # show the frame\n","        cv2.imshow(\"Frame\", frame)\n","        key = cv2.waitKey(1) & 0xFF\n","\n","        # if the `q` key was pressed, break from the loop\n","        if key == ord(\"q\"):\n","            break\n","\n","    # do a bit of cleanup\n","    cv2.destroyAllWindows()\n","    print('finish')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-39a86ff0c75f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    self.known_face_encodings = []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}]}]}